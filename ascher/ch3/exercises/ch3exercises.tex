\documentclass[12pt,a4]{article}

\usepackage{amsfonts,amsmath,amssymb,amsthm}
\usepackage{amscd}
\usepackage{mathtools}
\usepackage{geometry, algorithmicx} 
\usepackage[noend]{algpseudocode}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{dsfont}
\usepackage{fancyhdr}
\usepackage{enumerate}
\usepackage{pgf, tikz}
\usetikzlibrary{shapes,snakes}
\usetikzlibrary{arrows, automata}
\theoremstyle{definition}


\fancyhf{}
\fancyhead[LE,RO]{\thepage}
\fancyhead[CE]{\Author}
\fancyhead[CO]{\Title}
\renewcommand\headrulewidth{0pt}
\pagestyle{fancy}

\author{Colin Ford}
\title{Ascher - Chapter 3 Exercises}
\date{}

\makeatletter
\let\Title\@title
\makeatother

\newtheorem*{theorem*}{Theorem}
\newtheorem*{proposition*}{Proposition}
\newtheorem{problem}{Problem}
\newtheorem*{problem*}{Problem}
\newtheorem{exercise}{Exercise}
\newtheorem{lemma}{Lemma}
\newtheorem*{definition*}{Definition}
\newtheorem*{lemma*}{Lemma}
\newtheorem*{claim*}{Claim}
\newtheorem*{example}{Example}

\setcounter{exercise}{-1}

\begin{document}

\maketitle

% % % % % % % % % % %
% % % Problem 1 % % %
% % % % % % % % % % %
\begin{exercise}[Review Questions]
	\begin{enumerate}[(a)]
		% % a % %
		\item What is a nonlinear equation?
		
		% % b % %
		\item Is the bisection method (i) efficient? (ii) robust? Does it (iii) require a minimum amount of additional knowledge? (iv) require $f$ to satisfy only minimum smoothness properties? (v) generalize easily to several functions in several variables?
		
		% % c % %
		\item Answer similar questions for the Newton and Secant methods.
		
		% % d % %
		\item State at least one advantage and one disadvantage of the recursive implementation of the bisection method over the iterative nonrecursive implementation.
		
		% % e % %
		\item In what way is the fixed point iteration a \emph{family} of methods, rather than just one method like bisection or secant?
		
		% % f % %
		\item What is the basic condition for convergence of the fixed point iteration, and how does the speed of convergence relate to the derivative of the iteration function $g$?
		
		% % g % %
		\item Suppose a given fixed point iteration does not converge: does this mean that there is no root in the relevant interval? Answer a similar question for the Newton and secant methods. 
		
		% % h % %
		\item State at least two advantages and two disadvantages of Newton's method. 

		% % i % %
		\item What are order of convergence and rate of convergence, and how do they relate?
		
		% % j % %
		\item State at least one advantage and one disadvantage of the secant method over Newton's.
		
		% % k % %
		\item In what situation does Newton's method converge only linearly?
		
		% % l % %
		\item Explain the role that roundoff errors  play in the convergence of solvers for nonlinear equations, and explain their relationship with convergence errors.
		
		% % m % %
		\item State a similarity and a difference between the  problem of minimizing a function $\varphi(x)$ and that of solving the nonlinear equation $\varphi'(x) = 0$. 
		
		% % n % %
		\item State what a convex function is, and explain what happens if an objective function is convex. 
	\end{enumerate}
\end{exercise}
\begin{proof}[Solution]
	\begin{enumerate}[(a)]
		% % a % %
		\item A function $f$ is \emph{linear} if it satisfies the following two properties: 
		
		\begin{align*}
		f(x + y) &= f(x) + f(y) \\
		f(\alpha x) &= \alpha f(x) 
		\end{align*}
		
		where the first property is called additivity and the second homogeneity. Any function which does not satisfy these properties is called \emph{nonlinear}. 
		
		% % b % %
		\item The bisection method 
		\begin{enumerate}[(i)]
			% % i % %
			\item is not very time efficient; it is (relatively) slow.
			
			% % ii % %
			\item is robust; it will always find a root if one exists in the interval.
			
			% % iii % %
			\item only requires continuity of the function.
			
			% % iv % %
			\item (iii).
			
			% % v % %
			\item does not generalize easily to several functions in several variables.
		\end{enumerate}
		
		% % c % %
		\item Newton's method 
		\begin{enumerate}[(i)]
			% % i % %
			\item is basic and fast.
			
			% % ii % %
			\item is robust.
			
			% % iii % %
			\item requires that we know how to evaluate the derivative. 
			
			% % iv % %
			\item requires that we know the derivative exists.
			
			% % v % %
			\item does generalize easily.
		\end{enumerate}
	
		The secant method 
		\begin{enumerate}[(i)]
			% % i % %
			\item is fast.
		
			% % ii % %
			\item is robust.
		
			% % iii % %
			\item only requires continuity of the function.
		
			% % iv % %
			\item does not require that we know the derivative.
		
			% % v % %
			\item does not generalize easily to several functions in several variables.
		\end{enumerate}
		
		% % d % %
		\item An advantage of the recursive implementation is that it is incredibly short. A disadvantage is the fact that it is wasteful in terms of storage and potentially suboptimal in terms of CPU time. 
		
		% % e % %
		\item For a given problem $f(x) = 0$, we can define many functions $g$. 
		
		% % f % %
		\item If $g$ is continuous on the interval $[a, b]$ and $a \leq g(x) \leq b$ for all $a \leq x \leq b$, then there is a fixed point $x^*$ in the interval $[a, b]$. 
		
		If, in addition, the derivative $g'$ exists and there is a constant $\rho < 1$ such that the derivative satisfies
		
		\[
		|g'(x)| \leq \rho \quad \forall \ x \in (a, b) {,}
		\]
		
		\noindent then the fixed point is unique in this interval. This value of $\rho$ is directly related to the speed of convergence; the smaller $\rho$ is, the faster the iteration converges. 
		
		% % g % %
		\item Just because a given fixed point iteration does not mean there does not exist a root in the relevant interval; see Example 3.5. 
		
		% % h % %
		\item Two advantages of Newton's method are the fact that it is the most basic fast method for root finding, and that it can be directly extended to more general problems. Two disadvantages of Newton's method are (i) the need to know not only that the derivative exists but also how to evaluate it, and (ii) the local nature of the method's convergence. 
		
		% % i % %
		\item The order of convergence refers to the number $n$ in the equation
		
		\[
		|x_{k + 1} - x^*| \leq M |x_k - x^*|^n {.}
		\]
		
		\noindent The larger $n$ is the higher the rate of convergence.
		
		% % j % %
		\item The secant method does not require that the derivative exists. 
		
		% % k % %
		\item If, in addition to the assumptions that guarantee convergence in the Fixed Point Theorem, also $g'(x_0) \neq 0$, then the method converges linearly. See Exercise 3. 
		
		% % l % %
		\item 
		
		% % m % %
		\item Solving the nonlinear equation $\varphi'(x) = 0$ will produce a critical point $x^*$. This $x^*$ is a \emph{local minimizer} of $\varphi(x)$ if $\varphi''(x^*) > 0$.
		
		% % n % %
		\item A \emph{convex} function $\varphi$ is one that, for any two points $x, y \in [a, b]$ and for all $\theta \in [0, 1]$, satisfies
		
		\[
		\varphi(\theta x + (1 - \theta) y) \leq \theta \varphi(x) + (1 - \theta) \varphi(y) {.}
		\]
		
		\noindent If an objective function is convex, the problems of finding local and global minima coincide. 
	\end{enumerate}
\end{proof}

% % % % % % % % % % %
% % % Problem 2 % % %
% % % % % % % % % % %
\begin{exercise}
	 
\end{exercise}
\begin{proof}[Solution]
	
\end{proof}

% % % % % % % % % % %
% % % Problem 3 % % %
% % % % % % % % % % %
\begin{exercise}
	
\end{exercise}
\begin{proof}[Solution]
	
\end{proof}

% % % % % % % % % % %
% % % Problem 4 % % %
% % % % % % % % % % %
\begin{exercise}
	
\end{exercise}
\begin{proof}[Solution]
	
\end{proof}

% % % % % % % % % % %
% % % Problem 5 % % %
% % % % % % % % % % %
\begin{exercise}
	
\end{exercise}
\begin{proof}[Solution]
	
\end{proof}

% % % % % % % % % % %
% % % Problem 6 % % %
% % % % % % % % % % %
\begin{exercise}
	
\end{exercise}
\begin{proof}[Solution]
	
\end{proof}


\end{document}