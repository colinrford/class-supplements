\documentclass[12pt,a4]{article}

\usepackage{amsfonts,amsmath,amssymb,amsthm}
\usepackage{amscd}
\usepackage{mathtools}
\usepackage{geometry, algorithmicx} 
\usepackage[noend]{algpseudocode}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{dsfont}
\usepackage{fancyhdr}
\usepackage{enumerate}
\usepackage{hyperref}
\hypersetup{
	colorlinks,
	citecolor=black,
	filecolor=black,
	linkcolor=black,
	urlcolor=black
}
\usepackage{pgf, tikz}
\usetikzlibrary{shapes,snakes}
\usetikzlibrary{arrows, automata}
\theoremstyle{definition}


\fancyhf{}
\fancyhead[LE,RO]{\thepage}
\fancyhead[CE]{\Author}
\fancyhead[CO]{\Title}
\renewcommand\headrulewidth{0pt}
\pagestyle{fancy}

\author{Colin Ford}
\title{Ascher - Chapter 1 Exercises}
\date{}

\makeatletter
\let\Title\@title
\makeatother

\newtheorem*{theorem*}{Theorem}
\newtheorem*{proposition*}{Proposition}
\newtheorem{problem}{Problem}
\newtheorem*{problem*}{Problem}
\newtheorem{exercise}{Exercise}
\newtheorem{lemma}{Lemma}
\newtheorem*{definition*}{Definition}
\newtheorem*{lemma*}{Lemma}
\newtheorem*{claim*}{Claim}
\newtheorem*{example}{Example}

\setcounter{exercise}{-1}

\begin{document}

\maketitle

% % % % % % % % % % %
% % % Exercise 0 % % %
% % % % % % % % % % %
\begin{exercise}[Review Questions]
	\begin{enumerate}[(a)]
		% % a % %
		\item What is the difference, according to Section 1.1, between scientific computing and numerical analysis?
		
		% % b % %
		\item Give a sample example where relative error is a more suitable measure than absolute error, and another example where the absolute error measure is more suitable. 
		
		% % c % %
		\item State a major difference between the nature of roundoff errors and discretization errors.
		
		% % d % %
		\item Explain briefly why accumulation of roundoff errors is inevitable when arithmetic operations are performed in a floating point system. Under which circumstances is it tolerable in numerical computations?
		
		% % e % %
		\item Explain the differences between accuracy, efficiency, and robustness as criteria for evaluating an algorithm.
		
		% % f % %
		\item Show that nested evaluation of a polynomial of degree $n$ requires only $2n$ elementary operations and hence has $O(n)$ complexity.
		
		% % g % %
		\item Distinguish between problem conditioning and algorithm stability.
		
	\end{enumerate}
\end{exercise}
\begin{proof}[Solution]
	\begin{enumerate}[(a)]
		% % a % %
		\item \textbf{Scientific computing} is a discipline concerned with the development and study of numerical algorithms for solving mathematical problems that arise in various disciplines of science and engineering. 
		
		One seeks out algorithms which approximately solve a given mathematical problem efficiently, accurately and reliably; this is the heart of scientific computing. \textbf{Numerical analysis} may be viewed as the theory behind such algorithms. 
		
		% % b % %
		\item The relative error is usually a more meaningful measure. This is especially true for errors in floating point representation. Consider Example 1.1, where we observe the differences between the relative and absolute errors of the Stirling approximation. As $n$ grows larger, the relative error shrinks.
		
		% % c % %
		\item \textbf{Discretization errors} arise from discretizations of continuous processes, such as interpolation, differentiation and integration. \textbf{Roundoff errors} arise because of the finite precision representation of real numbers on any computer, which affects both data representation and computer arithmetic. 
		
		Unlike roundoff errors, discretization (and convergence) errors have a relatively smooth structure which may occasionally be exploited. 
		
		% % d % %
		\item 
		
		% % e % %
		\item When we talk of the accuracy of an algorithm, we refer to the magnitude of error to be expected when a computation is carried out. The accuracy of the algorithm will come down to the error bound within algorithm itself. 
		
		The efficiency of an algorithm refers to its use of CPU time as well as storage space. How an algorithm is implemented within a given computer language and the underlying hardware configuration also play a role in the efficiency of the algorithm.
		
		The robustness of an algorithm refers to how well it performs within its problem domain. A robust algorithm should handle all relevant and necessary cases well. Even if the algorithm fails to produce a ``correct result'', it should, for example, terminate with a warning. 
		
		% % f % %
		\item Nested evaluation of a polynomial only requires $n$ additions and $n$ multiplications, and hence $2n$ operations altogether. Thus we have $O(n)$ complexity. Indeed, given a polynomial of degree $n$, 
		
		\[
		p_n(x) = c_n x^n + \cdots + c_1 x + c_0 {,}
		\]
		
		\noindent its \emph{nested form} is 
		
		\[
		p_n(x) = (\cdots ((c_n x + c_{n - 1}) x + c_{n - 2}) x \cdots) x + c_0 {.}
		\]
		
		\noindent Observing the nested form or the algorithm on page 11, one sees it takes only $n$ multiplications and $n$ additions to evaluate $p_n(x)$ at a fixed point $x$. 
		
		% % g % %
		\item Problem conditioning falls into two categories: well-conditioned problems and ill-conditioned problems. If a problem is \textbf{Ill-conditioned}, even a small perturbation in the data will produce a large difference in the result. 
		
		The job of a \textbf{stable} algorithm for a given problem is to yield a numerical solution which is the exact solution of an only slightly perturbed problem. 
		
	\end{enumerate}
\end{proof}

% % % % % % % % % % %
% % % Exercise 1 % % %
% % % % % % % % % % %
\begin{exercise}
	Carry out calculations similar to those of Example 1.3 for approximating the derivative of the function $f(x) = e^{- 2 x}$ evaluated at $x_0 = 0.5$. Observe similarities and differences by comparing your graph against that in Figure 1.3. 
\end{exercise}
\begin{proof}[Solution]
	We use the following MATLAB script to generate the plot in Figure 1 below. 

	\begin{verbatim}
	x0 = 0.5;
	f0 = exp(-2*x0);
	fp = -2*f0;
	i = -20:0.5:0;
	h = 10.^i;
	err = abs (fp - (exp(-2*(x0+h)) - f0)./h);
	d_err = f0/2*h;
	loglog (h,err,'-*');
	hold on
	loglog (h,d_err,'r-.');
	xlabel('h')
	ylabel('Absolute error')
	\end{verbatim}
	
	\begin{figure}[h!]
		\centering
		\includegraphics[width=8cm]{exercise1fig.png}
		\caption{The combined effect of discretization and roundoff errors.  The solid blue curve interpolates the computed values of $|f'(x_0) - \frac{f(x_0 + h) - f(x_0)}{h}|$ for $f(x) = e^{-2 x}$, $x_0 = 0.5$. Also shown in dash-dot style is a straight line depicting the discretization error without the roundoff error.}
	\end{figure}

	\noindent One immediate difference the plot in Figure 1.3 in Example 1.3 and the plot here is the blue line. In Figure 1.3, the blue line dips below the red line and overall shows slightly more erratic behavior than the blue line suggests here. 
	
	The discretization error, represented by the red line, in the two graphs appears to be virtually the same. This makes sense since the process of discretization of similar continuous problems should be roughly the same on the same machine.\footnote{The language used here may be slightly incorrect. The same formula for the derivative was used on both problems. We expect the discretization error to be the same if using the same formula.}
	
	Both cases show that the roundoff error begins to dominate the discretization error around $10^{-8}$. 
\end{proof}

% % % % % % % % % % %
% % % Exercise 2 % % %
% % % % % % % % % % %
\begin{exercise}
	 Carry out derivation and calculations analogous to those in Example 1.2, using the expression
	 
	 \[
	 \frac{f(x_0 + h) - f(x_0 - h)}{2 h}
	 \]
	 
	 \noindent for approximating the first derivative $f'(x_0)$. Show that the error is $O(h^2)$. More precisely, the leading term of the error is $\frac{-h^2}{3} f'''(x_0)$ when $f'''(x_0) \neq 0$.
\end{exercise}
\begin{proof}[Solution]
	Counter to what was done in Example 1.2, for some small, negative value $h$, write 
	
	\[
	f(x_0 - h) = f(x_0) - h f'(x_0) + \frac{h^2}{2} f''(x_0) - \frac{h^3}{6} f'''(x_0) + \frac{h^4}{24} f^{(4)} (x_0) \mp \cdots {.}
	\]
	
	\noindent Then 
	
	\[
	f'(x_0) = \frac{f(x_0) - f(x_0 - h)}{h} + \frac{h}{2} f''(x_0) - \frac{h^2}{6} f'''(x_0) + \frac{h^3}{24} f^{(4)} (x_0) \mp \cdots {.} \tag{2.1} \label{eq:2.1}
	\]
	
	\noindent But we also have, from Example 1.2, that
	
	\[
	f'(x_0) = \frac{f(x_0 + h) - f(x_0)}{h} - \left( \frac{h}{2} f''(x_0) + \frac{h^2}{6} f'''(x_0) + \frac{h^3}{24} f^{(4)} (x_0) + \cdots \right) {.} \tag{2.2} \label{eq:2.2} 
	\]
	
	\noindent Adding \hyperref[eq:2.1]{\eqref{eq:2.1}} and \hyperref[eq:2.2]{\eqref{eq:2.2}}, we see that 
	
	\begin{align*}
	2 f'(x_0) &= \frac{f(x_0 + h) - f(x_0)}{h} + \frac{f(x_0) - f(x_0 - h)}{h} \\
	 &\quad - \left( \frac{h}{2} f''(x_0) + \frac{h^2}{6} f'''(x_0) + \frac{h^3}{24} f^{(4)} (x_0) + \cdots \right) \\
	 &\qquad + \frac{h}{2} f''(x_0) - \frac{h^2}{6} f'''(x_0) + \frac{h^3}{24} f^{(4)} (x_0) \mp \cdots \\
	 &= \frac{f(x_0 + h) - f(x_0 - h)}{h} - \frac{h^2}{3} f'''(x_0) - \frac{h^4}{60} f^{(5)} (x_0) - \cdots {.} \tag{2.3} \label{2.3}
	\end{align*}
	
	\noindent 
\end{proof}

% % % % % % % % % % %
% % % Exercise 3 % % %
% % % % % % % % % % %
\begin{exercise}
	Carry out similar calculations to those of Example 1.3 using the approximation from Exercise 2. Observe similarities and differences by comparing your graph against that in Figure 1.3. 
\end{exercise}
\begin{proof}[Solution]
	We use the following MATLAB script to generate the plot in Figure 1 below. 
	
	\begin{verbatim}
	x0 = 0.5;
	f0 = exp(-2*x0);
	fp = -2*f0;
	i = -20:0.5:0;
	h = 10.^i;
	err = abs (fp - (exp(-2*(x0+h)) - exp(-2*(x0-h)))./(2*h));
	d_err = f0/2*h;
	loglog (h,err,'-*');
	hold on
	loglog (h,d_err,'r-.');
	xlabel('h')
	ylabel('Absolute error')
	\end{verbatim}
	
	\noindent The differences between this plot and the previous plots are very noticeable. The previous plots were produced using similar estimates for the derivative, whereas this plot was produced using the estimate from Exercise 2. 
	
	It appears as though the roundoff error is more erratic, and begins its erratic behavior much before the previous situations did; in other words, the roundoff error begins to dominate the discretization error sooner than it did before. The absolute error in larger magnitudes of $h$ is also much better than in the previous cases. This is likely due to the $O(h^2)$ bound versus $O(h)$ bound.
	
	\begin{figure}[h!]
		\centering
		\includegraphics[width=8cm]{exercise3fig.png}
		\caption{The combined effect of discretization and roundoff errors.  The solid blue curve interpolates the computed values of $|f'(x_0) - \frac{f(x_0 + h) - f(x_0 - h)}{2h}|$ for $f(x) = e^{-2 x}$, $x_0 = 0.5$. Also shown in dash-dot style is a straight line depicting the discretization error without the roundoff error.}
	\end{figure}
	
\end{proof}

% % % % % % % % % % %
% % % Exercise 4 % % %
% % % % % % % % % % %
\begin{exercise}
	Following Example 1.5, assess the conditioning of the problem of evaluating
	
	\[
	g(x) = \tanh(c x) = \frac{\exp(c x) - \exp(- c x)}{\exp(c x) + \exp(- c x)} 
	\]
	
	\noindent near $x = 0$ as the positive parameter $c$ grows.
\end{exercise}
\begin{proof}[Solution]
	
\end{proof}

% % % % % % % % % % %
% % % Exercise 5 % % %
% % % % % % % % % % %
\begin{exercise}
	Consider the problem presented in Example 1.6. There we saw a numerically unstable procedure for carrying out the task.
	
	\begin{enumerate}[(a)]
		% % a % %
		\item Derive a formula for approximately computing these integrals based on evaluating $y_{n - 1}$ given $y_n$. 
		
		% % b % %
		\item Show that for any given value $\varepsilon > 0$ and positive integer $n_0$, there exists an integer $n_1 \geq n_0$ such that taking $y_{n_1} = 0$ as a starting value will produce integral evaluations $y_n$ with an absolute error smaller than $\varepsilon$ for all $0 < n \leq n_0$. 
		
		% % c % %
		\item Explain why your algorithm is stable.
		
		% % d % %
		\item Write a MATLAB function that computes the value of $y_{20}$ within an absolute error of at most $10^{- 5}$. Explain how you choose $n_1$ in this case. 
	\end{enumerate}
\end{exercise}
\begin{proof}[Solution]
	
\end{proof}


\end{document}